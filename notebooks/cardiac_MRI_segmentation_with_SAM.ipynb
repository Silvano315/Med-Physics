{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook project about testing SAM to segment Cardiac MRI scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Silvano315/Med-Physics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory\n",
    "\n",
    "import os \n",
    "\n",
    "os.chdir(\"Med-Physics\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your Kaggle API to /root/.config/kaggle and /root/.kaggle/kaggle.json\n",
    "\n",
    "os.makedirs('/root/.kaggle', exist_ok = True)\n",
    "\n",
    "!cp /content/drive/MyDrive/Kaggle_api/kaggle.json /root/.config/kaggle.json\n",
    "!cp /content/drive/MyDrive/Kaggle_api/kaggle.json /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "\n",
    "!pip install segment_anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/silvanoquarto/Desktop/LAVORO/MEDICAL_PHYSICS/Med-Physics'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you're running this repository LOCALLY, RUN this cell:\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "import kaggle\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from ipywidgets import interact\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set up device to use\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "\n",
    "data_dir = Path('data')\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kaggle_dataset(dataset_name : str = None, kaggle_url : str = None):\n",
    "    \"\"\"\n",
    "    Download ACDC dataset from Kaggle using Kaggle API.\n",
    "    Requires:\n",
    "    1. Kaggle account\n",
    "    2. API token (kaggle.json) in ~/.kaggle/\n",
    "    3. kaggle package installed: pip install kaggle\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = Path('data')\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading {dataset_name} dataset from Kaggle...\")\n",
    "    try:\n",
    "        kaggle.api.authenticate()\n",
    "        kaggle.api.dataset_download_files(\n",
    "            kaggle_url,\n",
    "            path=data_dir,\n",
    "            unzip=True\n",
    "        )\n",
    "        print(\"Dataset downloaded and extracted successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading dataset: {e}\")\n",
    "        print(\"\\nPlease ensure you have:\")\n",
    "        print(\"1. Created a Kaggle account\")\n",
    "        print(\"2. Generated an API token from https://www.kaggle.com/settings\")\n",
    "        print(\"3. Placed kaggle.json in ~/.kaggle/\")\n",
    "        print(\"4. Set appropriate permissions: chmod 600 ~/.kaggle/kaggle.json\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ACDC dataset from Kaggle...\n",
      "Dataset URL: https://www.kaggle.com/datasets/anhoangvo/acdc-dataset\n",
      "Dataset downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Download ACDC dataset from Kaggle using API key\n",
    "\n",
    "download_kaggle_dataset(dataset_name=\"ACDC\", kaggle_url='anhoangvo/acdc-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiac MRI Segmentation with SAM - Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SAM Model\n",
    "\n",
    "def setup_sam():\n",
    "    \"\"\"Initialize and load SAM model.\"\"\"\n",
    "\n",
    "    sam_checkpoint = \"sam_vit_b_01ec64.pth\"\n",
    "    checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "\n",
    "    if not os.path.exists(sam_checkpoint):\n",
    "        print(\"Downloading SAM checkpoint...\")\n",
    "        urllib.request.urlretrieve(checkpoint_url, sam_checkpoint)\n",
    "\n",
    "    model_type = \"vit_b\"\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=DEVICE)\n",
    "\n",
    "    return sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SAM checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silvanoquarto/Desktop/LAVORO/MEDICAL_PHYSICS/Med-Physics/.venv/lib/python3.11/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "sam = setup_sam()\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_h5_files(data_dir: Path, subset: str = 'training'):\n",
    "    \"\"\"\n",
    "    List all H5 files in the specified directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Base directory containing the dataset\n",
    "        subset: 'training' or 'testing'\n",
    "        \n",
    "    Returns:\n",
    "        List of paths to H5 files\n",
    "    \"\"\"\n",
    "    if 'training' in subset:\n",
    "        pattern = f\"**/*_{subset}/*.h5\"\n",
    "    else:\n",
    "        pattern = f\"**/*_{subset}_*/*.h5\"\n",
    "    \n",
    "    return list(data_dir.glob(pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_volumes_files = list_h5_files(data_dir, 'training_volumes')\n",
    "training_slices_files = list_h5_files(data_dir, 'training_slices')\n",
    "testing_volumes_files = list_h5_files(data_dir, 'testing')\n",
    "\n",
    "print(f\"Found {len(training_slices_files)} training slises \\\n",
    "and {len(training_volumes_files)} training volumes files \\\n",
    "and {len(testing_volumes_files)} testing volumes files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_info(file_lists: Dict[str, List[Path]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a DataFrame with information about the dataset files.\n",
    "    \n",
    "    Args:\n",
    "        file_lists: Dictionary with keys 'training_volumes', 'training_slices', 'testing_volumes'\n",
    "                   and corresponding lists of Path objects\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: patient_id, frame, slice (if applicable), type, path\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    pattern = r'patient(\\d+)_frame(\\d+)(?:_slice_(\\d+))?'\n",
    "    \n",
    "    for data_type, files in file_lists.items():\n",
    "        for file_path in files:\n",
    "            match = re.search(pattern, file_path.name)\n",
    "            if match:\n",
    "                patient_id = match.group(1)\n",
    "                frame = match.group(2)\n",
    "                slice_num = match.group(3)\n",
    "                \n",
    "                data_entry = {\n",
    "                    'patient_id': int(patient_id),\n",
    "                    'frame': int(frame),\n",
    "                    'slice': int(slice_num) if slice_num else None,\n",
    "                    'type': data_type,\n",
    "                    'path': str(file_path)\n",
    "                }\n",
    "                all_data.append(data_entry)\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    df = df.sort_values(['patient_id', 'frame', 'slice'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = {\n",
    "        'training_volumes': training_volumes_files,\n",
    "        'training_slices': training_slices_files,\n",
    "        'testing_volumes': testing_volumes_files\n",
    "    }\n",
    "\n",
    "dataset_df = create_dataset_info(file_lists)\n",
    "print(\"\\nDataset Overview:\")\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total files: {len(dataset_df)}\")\n",
    "print(\"\\nFiles per type:\")\n",
    "print(dataset_df['type'].value_counts())\n",
    "print(\"\\nUnique patients:\", dataset_df['patient_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_data(file_path: str):\n",
    "    \"\"\"\n",
    "    Load data from H5 file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to H5 file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing image and mask data\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        print(f\"Available keys in {Path(file_path).name}:\", list(f.keys()))\n",
    "        \n",
    "        data = {}\n",
    "        if 'image' in f:\n",
    "            data['image'] = f['image'][:]\n",
    "        if 'label' in f:\n",
    "            data['label'] = f['label'][:]\n",
    "        if 'scribble' in f:\n",
    "            data['scribble'] = f['scribble'][:]\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_volumes_files:\n",
    "        sample_data = load_h5_data(training_volumes_files[0])\n",
    "\n",
    "sample_data['image'], sample_data['label'], sample_data['scribble']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize 2D-3D MRI images with labels and scribbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slice_with_mask(image, label, scribble=None, title=\"Cardiac MRI Slice\"):\n",
    "    \"\"\"\n",
    "    Plot a cardiac MRI slice with optional overlay of the mask.\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array of the image\n",
    "        label: 2D numpy array of the label image\n",
    "        scribble: Optional 2D numpy array of the scribble mask\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if scribble is not None:\n",
    "        plt.imshow(scribble, alpha=0.3, cmap='jet')\n",
    "        plt.title(\"With Scribble\")\n",
    "    else:\n",
    "        plt.title(\"No Scribble\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(label, alpha=0.3, cmap='jet')\n",
    "    plt.title(\"With Label\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"{title}\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_slices_files:\n",
    "  sample = np.random.randint(0, len(training_slices_files))\n",
    "  sample_data = load_h5_data(training_slices_files[sample])\n",
    "  \n",
    "  if len(sample_data['image'].shape) == 3:\n",
    "      middle_slice = sample_data['image'].shape[2] // 2\n",
    "      image_slice = sample_data['image'][:, :, middle_slice]\n",
    "      mask_slice = sample_data['scribble'][:, :, middle_slice] if 'scribble' in sample_data else None\n",
    "  else:\n",
    "      image_slice = sample_data['image']\n",
    "      mask_slice = sample_data['scribble'] if 'scribble' in sample_data else None\n",
    "  \n",
    "plot_slice_with_mask(image_slice, sample_data['label'], mask_slice, \n",
    "                      f\"Sample from {Path(training_slices_files[sample]).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volume_slices(\n",
    "    volume: np.ndarray, \n",
    "    label: np.ndarray, \n",
    "    scribble: Optional[np.ndarray] = None, \n",
    "    start_slice: Optional[int] = None, \n",
    "    num_slices: int = 3, \n",
    "    step: Optional[int] = None, \n",
    "    title: str = \"Cardiac MRI Volumes\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot multiple slices from a 3D volume, optionally with overlayed labels and scribbles.\n",
    "\n",
    "    Args:\n",
    "      - volume (np.ndarray): The 3D volume to display, with shape (depth, height, width).\n",
    "      - label (np.ndarray): The 3D label mask to overlay, with shape (depth, height, width).\n",
    "      - scribble (Optional[np.ndarray]): An optional 3D scribble mask to overlay, with shape (depth, height, width).\n",
    "      - start_slice (Optional[int]): The starting slice index. If None, the function centers the slices.\n",
    "      - num_slices (int): The number of slices to display.\n",
    "      - step (Optional[int]): Step size between slices. Default is 1.\n",
    "      - title (str): The title for the entire figure.\n",
    "    \"\"\"\n",
    "    if start_slice is None:\n",
    "        middle = volume.shape[0] // 2\n",
    "        start_slice = middle - (num_slices // 2)\n",
    "    \n",
    "    if step is None:\n",
    "        step = 1\n",
    "\n",
    "    rows = 3 if scribble is not None else 2\n",
    "        \n",
    "    fig, axes = plt.subplots(rows, num_slices, figsize=(5 * num_slices, 5 * rows))\n",
    "    for i in range(num_slices):\n",
    "        slice_idx = start_slice + (i * step)\n",
    "        axes[0,i].imshow(volume[slice_idx], cmap='gray')\n",
    "        axes[0,i].set_title(f'Slice {slice_idx}', fontsize=20)\n",
    "        axes[0,i].axis('off')\n",
    "\n",
    "        axes[1,i].imshow(volume[slice_idx], cmap='gray')\n",
    "        axes[1,i].imshow(label[slice_idx], alpha = 0.3, cmap='jet')\n",
    "        axes[1,i].set_title('With Label', fontsize=20)\n",
    "        axes[1,i].axis('off')\n",
    "\n",
    "        if scribble is not None:\n",
    "          axes[2,i].imshow(volume[slice_idx], cmap='gray')\n",
    "          axes[2,i].imshow(scribble[slice_idx], alpha = 0.3, cmap='jet')\n",
    "          axes[2,i].set_title('With Scribble', fontsize=20)\n",
    "          axes[2,i].axis('off')\n",
    "\n",
    "    plt.suptitle(f'{title}', fontsize=28)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_volumes_files:\n",
    "  sample = np.random.randint(0, len(training_volumes_files))\n",
    "  sample_data = load_h5_data(training_volumes_files[sample])\n",
    "\n",
    "plot_volume_slices(sample_data['image'], label = sample_data['label'], \n",
    "                   scribble = sample_data['scribble'] if 'scribble' in sample_data else None,\n",
    "                   start_slice = 0, \n",
    "                   num_slices = sample_data['image'].shape[0], \n",
    "                   title = f\"Volumes Sample from {Path(training_volumes_files[sample]).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_slider(volume: np.ndarray, label: np.ndarray):\n",
    "    \"\"\"\n",
    "    Create an interactive slider to navigate the volume with the label side by side.\n",
    "    \n",
    "    Args:\n",
    "      - volume (np.ndarray): The 3D volume to be displayed (depth, height, width).\n",
    "      - label (np.ndarray): The 3D label mask corresponding to the volume.\n",
    "    \"\"\"\n",
    "    def view_slice(slice_idx: int):\n",
    "        plt.figure(figsize=(16, 8)) \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(volume[slice_idx], cmap='gray')\n",
    "        plt.title(f'Volume - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(volume[slice_idx], cmap='gray')\n",
    "        plt.imshow(label[slice_idx], alpha=0.3, cmap='jet')\n",
    "        plt.title(f'Volume con Label - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    interact(view_slice, slice_idx=(0, volume.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_slider(sample_data['image'], sample_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image):\n",
    "  \"\"\"Prepare medical image for SAM.\"\"\"\n",
    "  # Normalize to [0, 255]\n",
    "  image_norm = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)\n",
    "\n",
    "  # Convert to RGB by repeating the channel\n",
    "  image_rgb = np.stack([image_norm] * 3, axis=2)\n",
    "  return image_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "def get_internal_points(scribble, threshold=10):\n",
    "    \"\"\"\n",
    "    Takes the internal black dots from the scribble.\n",
    "    \"\"\"\n",
    "    scribble_min = np.min(scribble)\n",
    "    scribble_max = np.max(scribble)\n",
    "    \n",
    "    if scribble_min == scribble_max:\n",
    "        scribble = np.full_like(scribble, 255, dtype=np.uint8)\n",
    "    else:\n",
    "        scribble = ((scribble - scribble_min) / (scribble_max - scribble_min) * 255).astype(np.uint8)\n",
    "    \n",
    "    binary_scribble = scribble <= threshold\n",
    "    \n",
    "    filled_scribble = binary_fill_holes(binary_scribble)\n",
    "    \n",
    "    points_y, points_x = np.where(filled_scribble)\n",
    "    points = np.stack([points_x, points_y], axis=1)\n",
    "    \n",
    "    if len(points) > 50:\n",
    "        indices = np.random.choice(len(points), 10, replace=False)\n",
    "        points = points[indices]\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble = sample_data['scribble']\n",
    "internal_points = get_internal_points(scribble)\n",
    "plt.imshow(scribble, cmap='gray')\n",
    "plt.scatter(internal_points[:, 0], internal_points[:, 1], color='red', s=10)\n",
    "plt.title(\"Punti Interni dello Scribble\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = setup_sam()\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rgb = prepare_image(image_slice)\n",
    "predictor.set_image(image_rgb)\n",
    "        \n",
    "input_points = None\n",
    "input_labels = None\n",
    "\n",
    "normalized_scribble = ((sample_data['scribble'] - sample_data['scribble'].min()) / (sample_data['scribble'].max() - sample_data['scribble'].min()) * 255).astype(np.uint8)\n",
    "black_points = get_internal_points(normalized_scribble)\n",
    "input_points = black_points\n",
    "input_labels = np.ones(len(black_points))\n",
    "    \n",
    "boxes = None\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_points,\n",
    "    point_labels=input_labels,\n",
    "    box=boxes[0] if boxes is not None else None,\n",
    "    multimask_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(image, masks, scores, title=\"SAM Segmentation\"):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    if len(scores) > 0:\n",
    "        best_mask = masks[scores.argmax()]\n",
    "        plt.imshow(best_mask, alpha=0.5, cmap='jet')\n",
    "    plt.title(f\"Best Mask (score: {scores.max():.2f})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    for mask, score in zip(masks, scores):\n",
    "        color = np.random.rand(3)\n",
    "        plt.imshow(mask, alpha=0.3 * (score > 0.9), cmap='jet')\n",
    "    plt.title(\"All Masks\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(sample_data['image'], masks, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(sample_data['image'], cmap='gray')\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_points, input_labels, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Label\")\n",
    "plt.imshow(sample_data['image'], cmap='gray')\n",
    "plt.imshow(sample_data['label'], alpha = 0.3, cmap='jet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
